{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A.S. Lundervold, Oct. 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook and the next is meant to give you a taste of neural networks and deep learning. Deep learning is a very large field and the taste will be have to be quite small. The goal is to perhaps satisfy some of your curiosity (\"What is deep learning? How do you *do* deep learning\") and point you towards ways to learn more about the topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we'll see how to construct a basic deep neural network in PyTorch, and how to train it to perform a task. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=60% src=\"https://miro.medium.com/max/2400/1*aqNgmfyBIStLrf9k7d9cng.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some good, short sources to learn more about artificial neural networks and deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a better understanding of what neural networks are and how they work, I recommend watching the following two videos. They provide a nice high-level understanding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/aircAruvnKk\" \n",
       "frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen>\n",
       "</iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/aircAruvnKk\" \n",
    "frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen>\n",
    "</iframe>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/IHZwWFHWa-w\" \n",
       "frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen>\n",
       "</iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/IHZwWFHWa-w\" \n",
    "frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen>\n",
    "</iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here' a way to play around with neural networks directly in the browser: https://playground.tensorflow.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"450\"\n",
       "            src=\"https://playground.tensorflow.org\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f94f0090dc0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame('https://playground.tensorflow.org', width=800, height=450)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll construct what's called a *convolutional neural network*, the best kind of neural network for images (and more, see the lecture slides for details). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video width=60% autoplay loop> <source src=\"assets/CNN-viz-otavio-good.mp4\"> </video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<video width=60% autoplay loop> <source src=\"assets/CNN-viz-otavio-good.mp4\"> </video>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We won't cover how CNNs work in any detail, but the lecture will give some motivation for why one would want to do CNNs rather than standard fully-connected neural networks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more about how CNNs work, I recommend watching the video below. It gives a nice high-level introduction to convolutional neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/FmpDIaiMIeA\" \n",
       "frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen>\n",
       "</iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/FmpDIaiMIeA\" \n",
    "frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen>\n",
    "</iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommended literature and other resources\n",
    "See the course Canvas for recommended resources, including books and openly available courses, that go more in-depth into deep learning than the short videos above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/books.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><font size=\"-1\">Some recommended books. See Canvas for more.</font><center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a quick check of whether the notebook is currently running on Google Colaboratory, as that makes some difference for the code below.\n",
    "# We'll do this in every notebook of the course.\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    print('The notebook is running on Colab. colab=True.')\n",
    "    colab=True\n",
    "else:\n",
    "    print('The notebook is not running on Colab. colab=False.')\n",
    "    colab=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to True if you're using Gradient:\n",
    "gradient=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Google Colab and Paperspace Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If you're using your own computer and have followed the installation instructions in the course GitHub repository, PyTorch and other necessary libraries are already installed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if colab or gradient:\n",
    "    !pip3 install torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup libraries and folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "import urllib, tarfile, os, shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_DIR = Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this if you want to store the images that are downloaded\n",
    "# below elsewhere on your computer.\n",
    "if not gradient:\n",
    "    DATADIR = NB_DIR/'data'\n",
    "#    DATADIR = Path('/data2/alex/pcs-data')\n",
    "else:\n",
    "    DATADIR = Path('/storage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to our standard framework imported above, we'll need both torch and torchvision. If you remove the comment symbols (#) from the below cell and run it, pytorch and torchvision will be installed on your computer. Be patient, it may take some time to download the libraries.\n",
    "\n",
    "> If you've followed the installation instructions at "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if not colab and not gradient:\n",
    "#    import sys\n",
    "#    !conda install --yes --prefix {sys.prefix} -c pytorch pytorch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use a simple benchmark data set collected by Dr. Bradley J. Erickson M.D., Ph.D., from the Mayo Clinic, Rochester, USA (and also, by the way, head of the scientific advisory board of [MMIV](https://mmiv.no)), released under the Creative Commons CC BY-SA 4.0 license. \n",
    "\n",
    "It consists of 58.954 64x64 images from 6 different classes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/mednist.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to create a system that can recognize what class an image belongs to. That is, an **image classifier**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can download the data set from Dropbox:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(DATADIR/'MedNIST.tar.gz'):\n",
    "    urllib.request.urlretrieve(\"https://www.dropbox.com/s/5wwskxctvcxiuea/MedNIST.tar.gz?dl=1\", DATADIR/'MedNIST.tar.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... then extract it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(DATADIR/'MedNIST'):\n",
    "    shutil.unpack_archive(DATADIR/'MedNIST.tar.gz', extract_dir=DATADIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = DATADIR/'MedNIST'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch (and other deep learning frameworks) operate on what's called **tensors**, which are essentially multidimensional arrays that can be placed on GPUs for accellerated computing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To process the images we need to convert them to such tensors. We also need to create a way to organize the tensors and feed them to models. This can be accomplished by creating what's called a **data loader**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also make sure that the images are grayscale.\n",
    "transform = transforms.Compose([\n",
    "                        transforms.ToTensor(),                       # Convert the images to tensors \n",
    "                        transforms.Grayscale(num_output_channels=1)  # Convert the images to grayscale\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.ImageFolder(root=path, \n",
    "                                           transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = list(dataset.class_to_idx.keys())\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = torch.utils.data.random_split(dataset, [41267, 17687], \n",
    "                                                  generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot some images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are a few images and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)),  cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the next _batch_ of images and labels from the data loader\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show the images\n",
    "f = plt.figure(figsize=(18,12))\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print the corresponding labels\n",
    "print(f' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two stages to training a neural network: a forward pass to get values for all the nodes between the input and output, and a backward pass where backpropagation (based on what's called _automatic differentiation_ combined with _dynamic programming_) and gradient descent is used to tweak all the parameters in the network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make gradient descent work, we need to be able to take the derivative of each component in the network (these derivatives are computed during backpropagation). \n",
    "\n",
    "For details about these procedures, see http://cs231n.github.io/optimization-2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily PyTorch can take care of the differentiation for us (that is, the backward pass) if we create a network inheriting from `nn.Module`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A fully-connected neural net in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a simple one hidden layer neural network in PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 64*64*1 # The images are 64x64 grayscale (i.e. single channel images)\n",
    "hidden_size = 8      # We can choose this number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        \n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # A hidden layer\n",
    "        self.fc1 = torch.nn.Linear(input_size, hidden_size)\n",
    "        \n",
    "        # An output layer\n",
    "        self.fc2 = torch.nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    # We need to define what we want to happen in the forward phase (the backward phase is automatic)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Make the 64x64 image into a vector\n",
    "        x = x.view(x.size(0), -1) \n",
    "        \n",
    "        # Feed the input vector through the hidden layer and an activation function\n",
    "        x = torch.tanh(self.fc1(x)) \n",
    "        \n",
    "        # Output num_classes of numbers.\n",
    "        # We'll train the network to output a high number for the correct class\n",
    "        x = self.fc2(x) \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(input_size = input_size, hidden_size = hidden_size, num_classes = 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the steps for training a neural network are:\n",
    "1. Define a neural network (DONE)\n",
    "2. Collect a batch of training data (we'll use our trainloader)\n",
    "3. Send these through the network to get its predictions\n",
    "4. Measure the discrepancy between the true labels and the predictions using a loss function\n",
    "5. Update all the parameters using backpropagation (to calculate the gradients) and gradient descent (to update the parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the network on a single batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, lets take a look at a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the next batch\n",
    "i, data = next(enumerate(trainloader, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now collected the first batch of 4 images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(images), len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels of the first four are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...which means that the images are of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[classes[label] for label in labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images are torch tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Four images (batch size), 1 color channel, images of size 64x64. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feeding the batch to the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the output of the network from these images is simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, we got four vectors of length 6. Our goal is to make the element in each vector that corresponds to the correct label for the images in the batch as large as possible, while the rest are small. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we haven't trained our network at all yet, we can't expect it to produce any good predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted = torch.max(outputs.data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[classes[label] for label in predicted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[classes[label] for label in labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chances are none of the predictions are correct. If they are, that's just a coincidence. This is because we've initialized the network with random parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To measure the discrepancy between the output and the actual labels, we'll use something called **cross entropy loss**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the loss for our current batch: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(outputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `backward` method PyTorch can calculate how much each parameter in the network contributed to the loss by calculating the gradient of the loss with respect to each of them (using a technique called automatic differentation, which is related to the chain rule you know from your maths classes):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can update all the parameters using stochastic gradient descent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take one step with the optimizer to modify each parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network has now been trained *a tiny bit* (it has learned from the first four images). \n",
    "\n",
    "Let's see if that helped:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted = torch.max(outputs.data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network improved (on these four images on which it trained..). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Your turn!** Feed the next batch to the network and check how it performs on those."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going through the training data, batch by batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea now is to repeat this batch by batch, until we've been through the entire training data set multiple times. The idea is that gradient descent will then be able to find good settings for all the parameters, and we can use those when new data is fed through the network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first create a simple function for checking the accuracy of the network on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(net, dataloader=testloader):\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        # Feed all the test data through the net and count the number of correct predictions:\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "                outputs = net(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum()\n",
    "\n",
    "        accuracy = correct.numpy() / total\n",
    "            \n",
    "        print(f'The accuracy of the network on the test images is: {100 * accuracy}')\n",
    "        \n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our current accuracy after training on a single batch is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = check_accuracy(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the network is essentially untrained this is as expected (randomly guessing among the 6 classes gives an accuracy of 16.7%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the entire procedure for feeding batches through the network. You can CTRL+ENTER this cell to run it multiple times. You'll see the accuracy improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get next batch\n",
    "i, data = next(enumerate(trainloader, 0))\n",
    "images, labels = data\n",
    "# A technicality: we have to zero out the gradients each time, \n",
    "# otherwise they'll accumulate\n",
    "optimizer.zero_grad()\n",
    "# Collect the outputs\n",
    "outputs = net(images)\n",
    "# Compute the loss\n",
    "loss = criterion(outputs, labels)\n",
    "print(f'Current loss: {loss}')\n",
    "# Compute the gradients of the loss with respect to all the paremeters\n",
    "loss.backward()\n",
    "# Update the parameters using gradient descent\n",
    "optimizer.step()\n",
    "# Compute the current accuracy\n",
    "_ = check_accuracy(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Question:** How many times do you have to run the above cell to go through the entire training data set once? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll go through the entire training set 1 time. Feel free to increase this (but it'll take quite some time as we're running on the CPU, not the GPU [for now])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# First, we reset the model and the optimizer\n",
    "net = Net(input_size = input_size, hidden_size = hidden_size, num_classes = 6)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)\n",
    "\n",
    "# We record the accuracies during training for later analysis\n",
    "accuracies = [check_accuracy(net), ]\n",
    "\n",
    "for epoch in range(num_epochs): \n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.data\n",
    "        if i % 1000 == 999:    # print every 1000nd batch         \n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 1000))\n",
    "            \n",
    "            acc = check_accuracy(net)\n",
    "            \n",
    "            print(\"-\"*40)\n",
    "            accuracies.append(acc)\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Training complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the accuracy changes during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ylim([0.7, 1.0])\n",
    "plt.plot(accuracies, 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When doing classification, the **confusion matrix** is a very useful tool to evaluate our results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we collect lists of the predicted labels for the test data and the true labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        y_pred.append(list(predicted.numpy()))\n",
    "        y_true.append(list(labels.numpy()))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the lists (they are lists of sublists of length batch size)\n",
    "y_pred = [i for sublist in y_pred for i in sublist]\n",
    "y_true = [i for sublist in y_true for i in sublist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...then we compute and plot the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df_cm = pd.DataFrame(cm, classes, classes)\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(df_cm, annot=True, fmt=f'.0f', annot_kws={\"size\": 11}) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**That's it**, basically! Now you know the basics of training neural networks!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, our above neural network is not particularly powerful. Let's bring in some bigger guns to see what we can achieve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Your turn!** Try adding more neurons to the hidden layer. Also try adding a second hidden layer. How does it influence performance? Try experimenting with the sizes of the hidden layers. Are you able to obtain a better result than above?\n",
    "\n",
    "> Note: if you remove the \"check_accuracy\" call in the training loop it'll speed up the training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fundamentally, _\"deep learning\"_ for neural networks simply means adding more than one hidden layer: i.e. making the network deep. When you did the above \"Your turn!\" exercise, adding a second hidden layer, you actually _did deep learning_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, \"deep learning\" also refers to an entire field of research, chock-full of exciting ideas, models and techniques. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we discussed in the accompanying lecture, it's an extremely hot field that exploded a few years ago and is still growing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the areas where it has had the most impact is in **computer vision**, for example in **image classification**. In image classification the task is to assign an image to the correct class. If it's an image of a dog, it should be assigned to class \"dog\". \n",
    "\n",
    "That's exactly what we did above, using the MedNIST data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, our approach was pretty simple compared to what's available from deep learning. The most poweful types of neural networks for image analysis are the so-called **convolutional neural networks**. These are perhaps the most famous type of deep learning models out there. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lecture gave you some intuition for convolutional neural networks. Let's try to build one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<video width=60% autoplay loop> <source src=\"assets/CNN-viz-otavio-good.mp4\"> </video>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A CNN in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a very simple CNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting some parameters for the model\n",
    "kernel_size = 5\n",
    "out_channels = [10, 20]\n",
    "fc_features = [320, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # Convolution and pooling:\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=1, \n",
    "                                     out_channels=out_channels[0], \n",
    "                                     kernel_size=kernel_size)\n",
    "        \n",
    "        self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=out_channels[0], \n",
    "                                     out_channels=out_channels[1], \n",
    "                                     kernel_size=kernel_size)\n",
    "        \n",
    "        \n",
    "        # Some fully-connected layers at the end:\n",
    "        self.fc1 = torch.nn.Linear(in_features=3380, \n",
    "                                   out_features=fc_features[0])\n",
    "        \n",
    "        self.fc2 = torch.nn.Linear(in_features=fc_features[0], \n",
    "                                   out_features=fc_features[1])\n",
    "        \n",
    "        # Output layer:\n",
    "        self.fc3 = torch.nn.Linear(in_features=fc_features[1], \n",
    "                                   out_features=6)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(cnn.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "for epoch in range(num_epochs): \n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = cnn(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.data\n",
    "        if i % 1000 == 999:    # print every 1000nd batch         \n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 1000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Training complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = check_accuracy(cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = cnn(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        y_pred.append(list(predicted.numpy()))\n",
    "        y_true.append(list(labels.numpy()))        \n",
    "\n",
    "y_pred = [i for sublist in y_pred for i in sublist]\n",
    "y_true = [i for sublist in y_true for i in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "df_cm = pd.DataFrame(cm, classes, classes)\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(df_cm, annot=True, fmt=f'.0f', annot_kws={\"size\": 11}) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Your turn!** Try playing with the parameters we chose for our CNN. The kernel_size, the number of output channels (which is the *width* of the network) etc. You can also try adding another convolutional layer to the network to check whether that improves the  result. Note that the training time will increase as you increase the amount of parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trainable parameters for the current CNN model:\n",
    "sum(p.numel() for p in cnn.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If you want to make a really big and powerful model, you'll have to use a GPU.. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### *Next notebook: Taking some steps towards the state-of-the-art in deep learning*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pcs956",
   "language": "python",
   "name": "pcs956"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
